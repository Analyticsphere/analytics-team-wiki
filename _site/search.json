[
  {
    "objectID": "UsingBigQuery.html",
    "href": "UsingBigQuery.html",
    "title": "Using BigQuery",
    "section": "",
    "text": "Projects\n\ndev\n\n\nstg\n\n\nprod\n\n\n\nTables\n\n\nFlattening\n\n\nSaved Queries\n\n\nScheduled Queries\n\n\nConnecting to BigQuery in R\nWhen connecting to BigQuery with R there are two main options.\n\nbigrquery allows you to download the data directly to your local machine once you are authenticated. You can then manipulate the data directly in R. This is not a very salable approach because the data is overgrowing.\nDBI allows you to establish a “connection” to a BigQuery table and run your data manipulations and filters directly in BigQuery. This is preferable with large data sets.\n\nbigrquery example:\nlibrary(bigrquery)\nlibrary(glue)\n\nproject &lt;- 'nih-nci-dceg-connect-prod-6d04'\ndataset &lt;- 'FlatConnect'\ntable   &lt;- 'participants_noPII_JP'\nsql     &lt;- glue('SELECT * ',\n                'FROM `{project}.{dataset}.{table}` ',\n                'WHERE Connect_ID IS NOT NULL ',\n                'LIMIT 100')\n\n# Authenticate to BigQuery\nbigrquery::bq_auth()\n\n# Download data\ntb      &lt;- bigrquery::bq_project_query(project, query=sql)\ndata    &lt;- bigrquery::bq_table_download(tb, \n                                        bigint=\"integer64\", \n                                        page_size=1000)\nDBI example:\n\n\nConnecting to BigQuery in Python"
  },
  {
    "objectID": "surveyMetrics.html",
    "href": "surveyMetrics.html",
    "title": "Survey Metrics",
    "section": "",
    "text": "here is where kelsey could describe what reports she runs, where they are delivered, who reviews them, etcetera :)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "UsingGitHub.html",
    "href": "UsingGitHub.html",
    "title": "Using GitHub",
    "section": "",
    "text": "Analytics Team Repositories\n\n\nGitHub Best Practices"
  },
  {
    "objectID": "Team Roles.html",
    "href": "Team Roles.html",
    "title": "Team Roles",
    "section": "",
    "text": "Current Members\n\nNicole, Lead Analyst:\n\nThe boss\n\nJing, Senior Analyst:\n\n\n\nKelsey, Analyst:\n\n\n\nJake Peters, Data Scientist:\n\nGCP Pipelines, Flattening/Data Modeling, Box automation\n\nMadhuri, Analytics Coordinator\n\n\n\nRebecca, Analyst:\n\n\n\n\n\n\nPast Members"
  },
  {
    "objectID": "QAQC.html",
    "href": "QAQC.html",
    "title": "QAQC",
    "section": "",
    "text": "some content here"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to the Analytics Team Wiki",
    "section": "",
    "text": "Why a wiki?\nThis wiki is intended to gather the wealth of institutional knowledge that we have developed on this team into a persistent resource. This is especially useful for on-boarding new members, training colleagues to cover us while on PTO and for developing some overlapping knowledge across roles. We can also use this wiki to develop shared resources and formalize best practices that we would like to follow on our team as we grow and our work becomes more complex.\n\n\nWho should contribute?\nEveryone!\n\nIf you learn a new skill that could be useful to others, make a minimal tutorial and add it to the wiki!\nIf you create something new that will be part of the project for a while, add a documentation page to the wiki!\nIf you come across a resource that could be valuable to others, add a link to the wiki!\n\n\n\nHow to contribute\nYou can contribute a new page to the wiki in the form of an RMD file, QMD file, an MD file or an ipynb file. They can be easily added to the appropriate section using the _quarto.yml file, which ultimately configures how the site is rendered.\nThis is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n\nRules\n\nNever share PII or PHI on this site!\nNever share secret tokens or passwords.\nDo not share links to Box or other resources that do not require authentication.\nWhen in doubt, ask Jake."
  },
  {
    "objectID": "FlatteningIssues.html",
    "href": "FlatteningIssues.html",
    "title": "Data Structure",
    "section": "",
    "text": "Query:\nSELECT\n  LEFT(Connect_ID, 3) AS ID,\n  D_384191091_D_384191091_D_412790539 AS A,\n  D_384191091_D_384191091_D_458435048 AS B,\n  D_384191091_D_384191091_D_583826374 AS C,\n  D_384191091_D_384191091_D_586825330 AS D,\n  D_384191091_D_384191091_D_636411467 AS E,\n  D_384191091_D_384191091_D_706998638 AS F,\n  D_384191091_D_384191091_D_746038746 AS G,\n  D_384191091_D_384191091_D_807835037 AS H,\n  D_384191091_D_384191091_D_973565052 AS I,\n  D_384191091_D_747350323 AS OTHER\nFROM\n  `nih-nci-dceg-connect-stg-5519.FlatConnect.module1_v1_JP`\nWHERE \n  Connect_ID IN (\"1541654186\", \"6173331456\",\"3455671424\",\"2198619957\",\"1920159439\");\nResults:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nID\nA\nB\nC\nD\nE\nF\nG\nH\nI\nOTHER\n\n\n\n\n154\n0\n0\n0\n0\n0\n0\n0\n1\n0\nUnique\n\n\n192\n1\n1\n1\n1\n1\n1\n0\n1\n1\nTEST\n\n\n219\n0\n0\n0\n1\n1\n0\n0\n0\n0\nnull\n\n\n345\n0\n0\n0\n1\n0\n0\n0\n0\n0\nnull\n\n\n617\n0\n0\n0\n1\n1\n0\n0\n0\n0\nnull\n\n\n\n[{\n  \"ID\": \"154\",\n  \"A\": \"0\",\n  \"B\": \"0\",\n  \"C\": \"0\",\n  \"D\": \"0\",\n  \"E\": \"0\",\n  \"F\": \"0\",\n  \"G\": \"0\",\n  \"H\": \"1\",\n  \"I\": \"0\",\n  \"OTHER\": \"Unique\"\n}, {\n  \"ID\": \"192\",\n  \"A\": \"1\",\n  \"B\": \"1\",\n  \"C\": \"1\",\n  \"D\": \"1\",\n  \"E\": \"1\",\n  \"F\": \"1\",\n  \"G\": \"0\",\n  \"H\": \"1\",\n  \"I\": \"1\",\n  \"OTHER\": \"TEST\"\n}, {\n  \"ID\": \"219\",\n  \"A\": \"0\",\n  \"B\": \"0\",\n  \"C\": \"0\",\n  \"D\": \"1\",\n  \"E\": \"1\",\n  \"F\": \"0\",\n  \"G\": \"0\",\n  \"H\": \"0\",\n  \"I\": \"0\",\n  \"OTHER\": null\n}, {\n  \"ID\": \"345\",\n  \"A\": \"0\",\n  \"B\": \"0\",\n  \"C\": \"0\",\n  \"D\": \"1\",\n  \"E\": \"0\",\n  \"F\": \"0\",\n  \"G\": \"0\",\n  \"H\": \"0\",\n  \"I\": \"0\",\n  \"OTHER\": null\n}, {\n  \"ID\": \"617\",\n  \"A\": \"0\",\n  \"B\": \"0\",\n  \"C\": \"0\",\n  \"D\": \"1\",\n  \"E\": \"1\",\n  \"F\": \"0\",\n  \"G\": \"0\",\n  \"H\": \"0\",\n  \"I\": \"0\",\n  \"OTHER\": null\n}]\nQuery 2:\nSELECT\n  LEFT(CAST(Connect_ID AS String), 3) AS ID,\n  D_384191091.D_384191091 AS Race,\n  D_384191091.D_747350323 AS Other\n  FROM\n  `nih-nci-dceg-connect-stg-5519.Connect.module1_v1`\nWHERE Connect_ID IN (1541654186, 6173331456,3455671424,2198619957,1920159439);\nResults 2:\n\n\n\nRow\nID\nRace\nOther\n\n\n\n\n\n\n586825330\n\n\n\n3\n345\n586825330\nnull\n\n\n4\n219\n636411467\nnull\n\n\n\n\n586825330\n\n\n\n5\n192\n583826374\nTEST\n\n\n\n\n636411467\n\n\n\n\n\n458435048\n\n\n\n\n\n706998638\n\n\n\n\n\n973565052\n\n\n\n\n\n586825330\n\n\n\n\n\n412790539\n\n\n\n\n\n807835037\n\n\n\n\n[{\n  \"ID\": \"154\",\n  \"Race\": [\"807835037\"],\n  \"Other\": \"Unique\"\n}, {\n  \"ID\": \"617\",\n  \"Race\": [\"636411467\", \"586825330\"],\n  \"Other\": null\n}, {\n  \"ID\": \"345\",\n  \"Race\": [\"586825330\"],\n  \"Other\": null\n}, {\n  \"ID\": \"219\",\n  \"Race\": [\"636411467\", \"586825330\"],\n  \"Other\": null\n}, {\n  \"ID\": \"192\",\n  \"Race\": [\"583826374\", \"636411467\", \"458435048\", \"706998638\", \"973565052\", \"586825330\", \"412790539\", \"807835037\"],\n  \"Other\": \"TEST\"\n}]"
  },
  {
    "objectID": "optimizing-data-handling.html",
    "href": "optimizing-data-handling.html",
    "title": "Optimizing Data Handling with R and BigQuery",
    "section": "",
    "text": "As our dataset continues to grow, optimizing data handling becomes paramount for computational efficiency and memory usage. This tutorial explores four methods to achieve these goals, focusing on offloading computation to BigQuery through SQL queries. By following simple rules, such as being selective about data loading and leveraging Materialized Views, you can streamline your data workflows and make them more efficient."
  },
  {
    "objectID": "using-bigquery.html",
    "href": "using-bigquery.html",
    "title": "Using BigQuery",
    "section": "",
    "text": "Projects\n\ndev\n\n\nstg\n\n\nprod\n\n\n\nTables\n\n\nFlattening\n\n\nSaved Queries\n\n\nScheduled Queries\n\n\nConnecting to BigQuery in R\nWhen connecting to BigQuery with R there are two main options.\n\nbigrquery allows you to download the data directly to your local machine once you are authenticated. You can then manipulate the data directly in R. This is not a very salable approach because the data is overgrowing.\nDBI allows you to establish a “connection” to a BigQuery table and run your data manipulations and filters directly in BigQuery. This is preferable with large data sets.\n\nbigrquery example:\nlibrary(bigrquery)\nlibrary(glue)\n\nproject &lt;- 'nih-nci-dceg-connect-prod-6d04'\ndataset &lt;- 'FlatConnect'\ntable   &lt;- 'participants_noPII_JP'\nsql     &lt;- glue('SELECT * ',\n                'FROM `{project}.{dataset}.{table}` ',\n                'WHERE Connect_ID IS NOT NULL ',\n                'LIMIT 100')\n\n# Authenticate to BigQuery\nbigrquery::bq_auth()\n\n# Download data\ntb      &lt;- bigrquery::bq_project_query(project, query=sql)\ndata    &lt;- bigrquery::bq_table_download(tb, \n                                        bigint=\"integer64\", \n                                        page_size=1000)\nDBI example:\n\n\nConnecting to BigQuery in Python"
  },
  {
    "objectID": "survey-metrics.html",
    "href": "survey-metrics.html",
    "title": "Survey Metrics",
    "section": "",
    "text": "here is where kelsey could describe what reports she runs, where they are delivered, who reviews them, etcetera :)"
  },
  {
    "objectID": "using-github.html",
    "href": "using-github.html",
    "title": "Using GitHub",
    "section": "",
    "text": "Analytics Team Repositories\n\n\nGitHub Best Practices"
  },
  {
    "objectID": "flattening.html",
    "href": "flattening.html",
    "title": "Flattening",
    "section": "",
    "text": "content"
  },
  {
    "objectID": "team-roles.html",
    "href": "team-roles.html",
    "title": "Team Roles",
    "section": "",
    "text": "Current Members\n\nNicole, Lead Analyst:\n\nThe boss\n\nJing, Senior Analyst:\n\n\n\nKelsey, Analyst:\n\n\n\nJake Peters, Data Scientist:\n\nGCP Pipelines, Flattening/Data Modeling, Box automation\n\nMadhuri, Analytics Coordinator\n\n\n\nRebecca, Analyst:\n\n\n\n\n\n\nPast Members"
  },
  {
    "objectID": "optimizing-data-handling.html#benchmarking",
    "href": "optimizing-data-handling.html#benchmarking",
    "title": "Optimizing Data Handling with R and BigQuery",
    "section": "Benchmarking",
    "text": "Benchmarking\nTo determine which method is most efficient, let’s benchmark each approach.\nlibrary(microbenchmark)\n\n# Benchmark each method\nbenchmark_results &lt;- microbenchmark(\n  Method1 = method1_function(project_id, dataset, table),\n  Method2 = method2_function(project_id, dataset, table),\n  Method3 = method3_function(project_id, dataset, table),\n  Method4 = method4_function(project_id, dataset, table),\n  times = 100\n)\n\n# Compare and summarize the benchmark results\nsummary(benchmark_results)"
  },
  {
    "objectID": "optimizing-data-handling.html#dataset-description-and-transformations",
    "href": "optimizing-data-handling.html#dataset-description-and-transformations",
    "title": "Optimizing Data Handling",
    "section": "Dataset Description and Transformations",
    "text": "Dataset Description and Transformations\nIn this tutorial, we are working with the “bigquery-public-data.samples.natality” dataset, which contains data related to births. Specifically, it includes information about newborns such as gender, birth weight, and source of the data.\n\nTransformations Across All Methods\nIn each method, we perform the following common transformations on the dataset:\n\nFiltering for Male Newborns: We filter the dataset to include only records for male newborns by applying the condition is_male == 1.\nInner Join with Itself: We perform an inner join with the same dataset based on the “source” column. This join duplicates the dataset, and each row is matched with another row from the same dataset.\nWeight Conversion: We calculate the birth weight in kilograms (birth_weight_kg) by converting the weight from pounds to kilograms using the conversion factor of 0.453592.\n\nThese transformations are applied consistently across all methods to demonstrate the different ways of loading and processing the data from BigQuery into R. The choice of method may affect the efficiency and ease of performing these transformations.\n\n\n0. Load dependencies & parameterize\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:dbplyr':\n\n    ident, sql\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\n\n1. Load data, then process\n\nmethod1_function &lt;- function(project_id, dataset, table) {\n  # Build the SQL query using glue\n  sql_query &lt;- glue::glue(\"SELECT * FROM `{project_id}.{dataset}.{table}` WHERE is_male = 1\")\n  \n  # Execute the query\n  query_result &lt;- bigrquery::bq_query(sql_query)\n  \n  # Fetch and process the data\n  result &lt;- bigrquery::bq_table_download(query_result)\n  result &lt;- dplyr::filter(result, is_male == 1)\n  result &lt;- dplyr::inner_join(result, result, by = \"source\")\n  result &lt;- dplyr::mutate(result, birth_weight_kg = weight_pounds * 0.453592)\n  return(result)\n}\n\n\n\n2. Process with SQL, then load\n\nmethod2_function &lt;- function(project_id, dataset, table) {\n  # Build the SQL query using glue\n  sql_query &lt;- glue::glue(\n    \"SELECT * FROM `{project_id}.{dataset}.{table}` WHERE is_male = 1\"\n    )\n  \n  # Execute the query\n  query_result &lt;- bigrquery::bq_query(sql_query)\n  \n  # Fetch and process the data\n  result &lt;- bigrquery::bq_table_download(query_result)\n  result &lt;- dplyr::inner_join(result, result, by = \"source\")\n  result &lt;- dplyr::mutate(result, birth_weight_kg = weight_pounds * 0.453592)\n  return(result)\n}\n\n\n\n3. Process with dbConnect & dbplyr, then load\n\nmethod3_function &lt;- function(project_id, dataset, table) {\n  # Establish a database connection\n  con &lt;- DBI::dbConnect(bigrquery::bigquery(), project = project_id, dataset = dataset)\n  \n  # Query and process the data using dbplyr\n  data &lt;- dbplyr::tbl(con, table) %&gt;%\n    dplyr::filter(is_male == 1) %&gt;%\n    dplyr::inner_join(dbplyr::tbl(con, table), by = \"source\") %&gt;%\n    dplyr::mutate(birth_weight_kg = weight_pounds * 0.453592)\n  \n  # Disconnect from the database\n  DBI::dbDisconnect(con)\n  return(data)\n}\n\n\n\nProcess as Materialized View, then load\nCREATE MATERIALIZED VIEW `your_project.your_dataset.your_materialized_view` AS\nSELECT\n  column1,\n  column2,\n  SUM(sales_amount) AS total_sales\nFROM\n  `your_project.your_dataset.sales_data`\nGROUP BY\n  column1, column2;\nmethod4_function &lt;- function(project_id, dataset, table) {\n  # Build the SQL query using glue\n  sql_query &lt;- glue::glue(\"SELECT * FROM `{project_id}.{dataset}.{table}_materialized_view`\")\n  \n  # Execute the query\n  query_result &lt;- bigrquery::bq_query(sql_query)\n  \n  # Fetch and process the data\n  result &lt;- bigrquery::bq_table_download(query_result)\n  result &lt;- dplyr::inner_join(result, result, by = \"source\")\n  result &lt;- dplyr::mutate(result, birth_weight_kg = weight_pounds * 0.453592)\n  return(result)\n}"
  },
  {
    "objectID": "optimizing-data-handling.html#conclusions",
    "href": "optimizing-data-handling.html#conclusions",
    "title": "Optimizing Data Handling with R and BigQuery",
    "section": "Conclusions",
    "text": "Conclusions\nIn conclusion, the choice of data handling method in BigQuery and R depends on your specific needs. If simplicity and familiarity are your priorities, Method 1 may be suitable. For those proficient in SQL, Method 2 provides efficiency. Method 3 combines SQL and R flexibility, while Method 4 excels in efficiency and preprocessed data. By understanding these methods, you can optimize your data workflows and make informed decisions, improving your data analysis projects."
  },
  {
    "objectID": "optimizing-data-handling.html#simple-rules-for-optimization",
    "href": "optimizing-data-handling.html#simple-rules-for-optimization",
    "title": "Optimizing Data Handling with R and BigQuery",
    "section": "Simple Rules for Optimization",
    "text": "Simple Rules for Optimization\nTo ensure efficient data handling, let’s agree on some simple rules:\n\nBe Selective: Load only the variables you need.\nLeverage BigQuery: Perform filters, joins, and manipulations in BigQuery using SQL or dbConnect/dbplyr.\nUse Views: Consider creating Materialized Views in BigQuery for repetitive operations."
  },
  {
    "objectID": "optimizing-data-handling.html#methods-and-links",
    "href": "optimizing-data-handling.html#methods-and-links",
    "title": "Optimizing Data Handling with R and BigQuery",
    "section": "Methods and Links",
    "text": "Methods and Links\n\nUsing dbConnect and dbplyr:\n\nIntroduction to dbplyr\ndbplyr SQL translation\nSQL queries in RMD\n\nQuerying BigQuery using SQL directly in rmarkdown:\n\nRMD and SQL"
  },
  {
    "objectID": "optimizing-data-handling.html#about-the-example-data-and-analysis",
    "href": "optimizing-data-handling.html#about-the-example-data-and-analysis",
    "title": "Optimizing Data Handling with R and BigQuery",
    "section": "About the Example Data and Analysis",
    "text": "About the Example Data and Analysis\nIn this tutorial, we work with the “bigquery-public-data.samples.natality” dataset, containing information related to births, including details about newborns like gender, birth weight, and data source."
  },
  {
    "objectID": "optimizing-data-handling.html#transformations-across-all-methods",
    "href": "optimizing-data-handling.html#transformations-across-all-methods",
    "title": "Optimizing Data Handling with R and BigQuery",
    "section": "Transformations Across All Methods",
    "text": "Transformations Across All Methods\nCommon transformations are performed in each method:\n\nFiltering for Male Newborns: Include only records for male newborns (is_male == 1).\nInner Join with Itself: Perform an inner join with the same dataset based on the “source” column, duplicating the dataset.\nWeight Conversion: Calculate birth weight in kilograms (birth_weight_kg) by converting pounds to kilograms (0.453592)."
  },
  {
    "objectID": "optimizing-data-handling.html#methods-of-loading-and-processing-data-from-bigquery-in-r",
    "href": "optimizing-data-handling.html#methods-of-loading-and-processing-data-from-bigquery-in-r",
    "title": "Optimizing Data Handling with R and BigQuery",
    "section": "4 Methods of Loading and Processing Data from BigQuery in R",
    "text": "4 Methods of Loading and Processing Data from BigQuery in R\nThis tutorial explores four distinct methods for efficiently loading and processing data from BigQuery in the R programming language. Handling large datasets and performing data transformations is a fundamental aspect of data science and analytics. As data scientists and engineers, it’s crucial to adopt practices that optimize computational efficiency, memory usage, and maintainability in our data workflows.\nIn this tutorial, we delve into four distinct approaches, each with its own set of advantages and considerations.\n\nLoad dependencies & parameterize\nlibrary(bigrquery)\nlibrary(DBI)\nlibrary(dbplyr)\nlibrary(dplyr)\n\n# Define project, dataset, and table IDs\nproject_id &lt;- \"bigquery-public-data\"\ndataset    &lt;- \"samples\"\ntable      &lt;- \"natality\"\n\n\nMethod 1: Using bq_table_download\nIn Method 1, we load data using bq_table_download in BigQuery, then perform data filtering, transformations, and joins in the local R environment.\nmethod1_function &lt;- function(project_id, dataset, table) {\n  # Build the SQL query using glue\n  sql_query &lt;- glue::glue(\"SELECT * FROM `{project_id}.{dataset}.{table}` WHERE is_male = 1\")\n  \n  # Execute the query\n  query_result &lt;- bigrquery::bq_query(sql_query)\n  \n  # Fetch and process the data\n  result &lt;- bigrquery::bq_table_download(query_result) %&gt;%\n    dplyr::filter(result, is_male == 1) %&gt;%\n    dplyr::inner_join(result, result, by = \"source\") %&gt;% \n    dplyr::mutate(result, birth_weight_kg = weight_pounds * 0.453592)\n  return(result)\n}\n\ndf1 &lt;- method1_function(project_id, dataset, table)\nhead(df1)\nPros\n\nSimplicity: This method is straightforward and easy to use, making it suitable for quick data retrieval.\nIntuitive Data Manipulation: Data manipulation in R after downloading is more intuitive, allowing for easy filtering, joining, and transformation using familiar R functions.\n\nCons\n\nData Volume Limitation: May not be suitable for very large datasets as it loads the entire table into memory, potentially causing memory issues.\nAdditional Code for Transformation: Requires additional R code for filtering, joining, and transformation after downloading.\n\n\n\nMethod 2: Process with SQL in BigQuery\nMethod 2 leverages the power of SQL within BigQuery to perform all data processing, including filtering, joining, and birth weight calculations, directly in the SQL query within BigQuery itself. This approach minimizes the need for additional R data manipulation.\nLet’s create an SQL query in BigQuery that handles all the required data transformations:\n# Build the SQL query using glue to perform all data processing in BigQuery\nsql_query &lt;- glue::glue(\n  \"SELECT\n    t1.*,\n    t2.*,\n    weight_pounds * 0.453592 AS birth_weight_kg\n  FROM\n    `{project_id}.{dataset}.{table}` AS t1\n  JOIN\n    `{project_id}.{dataset}.{table}` AS t2\n  ON\n    t1.source = t2.source\n  WHERE\n    t1.is_male = 1\"\n)\n\n# Execute the query\nquery_result &lt;- bigrquery::bq_query(sql_query)\n\n# Fetch the processed data directly from BigQuery\nresult &lt;- bigrquery::bq_table_download(query_result)\nPros\n\nSQL Expertise: Ideal for users with SQL expertise, as data filtering, joining, and transformation can be done entirely in SQL, leveraging the power of BigQuery.\nEfficiency: SQL queries can be optimized for efficient data retrieval and processing within BigQuery.\n\nCons\n\nSQL Knowledge Required: Requires proficiency in SQL for writing complex queries, which may not be suitable for all R users.\nPotential for Complex SQL: Complex SQL queries can become difficult to manage and debug.\n\n\n\nMethod 3: Using dbConnect and dbplyr\nIn Method 3, we establish a database connection and leverage dbplyr to perform data filtering, joins, and transformations directly in BigQuery. This method combines SQL and R flexibility while utilizing lazy evaluation.\nmethod3_function &lt;- function(project_id, dataset, table) {\n  # Establish a database connection\n  con &lt;- DBI::dbConnect(bigrquery::bigquery(), project = project_id, dataset = dataset)\n  \n  # Query and process the data using dbplyr\n  data &lt;- dbplyr::tbl(con, table) %&gt;%\n    dplyr::filter(is_male == 1) %&gt;%\n    dplyr::inner_join(dbplyr::tbl(con, table), by = \"source\") %&gt;%\n    dplyr::mutate(birth_weight_kg = weight_pounds * 0.453592)\n  \n  # Disconnect from the database\n  DBI::dbDisconnect(con)\n  return(data)\n}\n\ndf3 &lt;- method2_function(project_id, dataset, table)\nhead(df3)\nPros\n\nLazy Evaluation: Utilizes lazy evaluation, allowing you to build and optimize the query step by step, enhancing query efficiency.\nSQL and R Integration: Offers the benefits of both SQL and R, making it flexible for users with varying levels of SQL expertise.\n\nCons\n\nDatabase Connection Overhead: Establishing and managing a database connection can add some overhead to the process.\nLearning Curve: Users not familiar with dbplyr may need time to learn and adapt to this method.\n\n\n\nMethod 4: Using “Materialized View” in BigQuery\nMethod 4 involves creating a materialized view in BigQuery that includes all data filtering, transformations, and joins. We access preprocessed data directly from the view, reducing the need for complex transformations in R.\nCreate a Materialized View in BigQuery:\nCREATE MATERIALIZED VIEW `your_project.your_dataset.your_materialized_view` AS\nSELECT\n  column1,\n  column2,\n  SUM(sales_amount) AS total_sales,\n  weight_pounds * 0.453592 AS birth_weight_kg\nFROM\n  `your_project.your_dataset.sales_data`\nWHERE\n  is_male = 1\nGROUP BY\n  column1, column2, birth_weight_kg;\nAccessing Data from the Materialized View\nNow, let’s load and process data using Method 4, where all data analysis is performed within the SQL query that generates the materialized view. We won’t need additional R data manipulation in this method.\nmethod4_function &lt;- function(project_id, dataset, table) {\n  # Build the SQL query to directly access the materialized view\n  sql_query &lt;- glue::glue(\"SELECT * FROM `{project_id}.{dataset}.{table}_materialized_view`\")\n  \n  # Execute the query\n  query_result &lt;- bigrquery::bq_query(sql_query)\n  \n  # Fetch the data directly from the materialized view\n  result &lt;- bigrquery::bq_table_download(query_result)\n  \n  return(result)\n}\n\ndf4 &lt;- method4_function(project_id, dataset, table)\nhead(df4)\nPros\n\nPreprocessed Data: Materialized views in BigQuery store preprocessed and aggregated data, reducing the need for complex transformations in R.\nEfficiency: Retrieving data from a materialized view is often faster than processing raw data.\n\nCons\n\nLimited Flexibility: Materialized views are predefined, limiting flexibility for custom transformations or ad-hoc queries.\nMaintenance: Materialized views require maintenance to ensure they stay up-to-date with source data changes."
  },
  {
    "objectID": "optimizing-data-handling.html#verification",
    "href": "optimizing-data-handling.html#verification",
    "title": "Optimizing Data Handling with R and BigQuery",
    "section": "Verification",
    "text": "Verification\nTo ensure the correctness of our methods, we’ll verify that the data frames returned by each method are identical.\n# Verify data frame equality\nidentical_df1_df2 &lt;- identical(df1, df2)\nidentical_df1_df3 &lt;- identical(df1, df3)\nidentical_df1_df4 &lt;- identical(df1, df4)\nidentical_df2_df3 &lt;- identical(df2, df3)\nidentical_df2_df4 &lt;- identical(df2, df4)\nidentical_df3_df4 &lt;- identical(df3, df4)\n\n# Display data frame equality verification\ncat(\"Data Frame Equality Verification:\\n\")\ncat(\"Method 1 and Method 2: \", identical_df1_df2, \"\\n\")\ncat(\"Method 1 and Method 3: \", identical_df1_df3, \"\\n\")\ncat(\"Method 1 and Method 4: \", identical_df1_df4, \"\\n\")\ncat(\"Method 2 and Method 3: \", identical_df2_df3, \"\\n\")\ncat(\"Method 2 and Method 4: \", identical_df2_df4, \"\\n\")\ncat(\"Method 3 and Method 4: \", identical_df3_df4, \"\\n\")"
  },
  {
    "objectID": "optimizing-data-handling.html#references-and-helpful-links",
    "href": "optimizing-data-handling.html#references-and-helpful-links",
    "title": "Optimizing Data Handling with R and BigQuery",
    "section": "References and Helpful Links",
    "text": "References and Helpful Links\n\nUsing dbConnect and dbplyr:\n\nIntroduction to dbplyr\ndbplyr SQL translation\nSQL queries in RMD\n\nQuerying BigQuery using SQL directly in rmarkdown:\n\nRMD and SQL"
  },
  {
    "objectID": "optimizing-data-handling.html#methods-for-downloadingmanipulating-bq-data",
    "href": "optimizing-data-handling.html#methods-for-downloadingmanipulating-bq-data",
    "title": "Optimizing Data Handling with R and BigQuery",
    "section": "4 Methods for Downloading/Manipulating BQ data",
    "text": "4 Methods for Downloading/Manipulating BQ data\n\nAbout the Example Data and Analysis\nIn this tutorial, we work with the “bigquery-public-data.samples.natality” dataset, containing information related to births, including details about newborns like gender, birth weight, and data source.\n\n\nTransformations Across All Methods\nCommon transformations are performed in each method:\n\nFiltering for Male Newborns: Include only records for male newborns (is_male == 1).\nInner Join with Itself: Perform an inner join with the same dataset based on the “source” column, duplicating the dataset.\nWeight Conversion: Calculate birth weight in kilograms (birth_weight_kg) by converting pounds to kilograms (0.453592)."
  }
]